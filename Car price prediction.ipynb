{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"car_dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Present_Price</th>\n",
       "      <th>Kms_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Seller_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ritz</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.59</td>\n",
       "      <td>27000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sx4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.54</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.25</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6900</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wagon r</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5200</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swift</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.87</td>\n",
       "      <td>42450</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>city</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>33988</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>brio</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>60000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>city</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.00</td>\n",
       "      <td>87934</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>city</td>\n",
       "      <td>2017</td>\n",
       "      <td>11.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>9000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>brio</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5464</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type  \\\n",
       "0       ritz  2014           3.35           5.59       27000    Petrol   \n",
       "1        sx4  2013           4.75           9.54       43000    Diesel   \n",
       "2       ciaz  2017           7.25           9.85        6900    Petrol   \n",
       "3    wagon r  2011           2.85           4.15        5200    Petrol   \n",
       "4      swift  2014           4.60           6.87       42450    Diesel   \n",
       "..       ...   ...            ...            ...         ...       ...   \n",
       "296     city  2016           9.50          11.60       33988    Diesel   \n",
       "297     brio  2015           4.00           5.90       60000    Petrol   \n",
       "298     city  2009           3.35          11.00       87934    Petrol   \n",
       "299     city  2017          11.50          12.50        9000    Diesel   \n",
       "300     brio  2016           5.30           5.90        5464    Petrol   \n",
       "\n",
       "    Seller_Type Transmission  Owner  \n",
       "0        Dealer       Manual      0  \n",
       "1        Dealer       Manual      0  \n",
       "2        Dealer       Manual      0  \n",
       "3        Dealer       Manual      0  \n",
       "4        Dealer       Manual      0  \n",
       "..          ...          ...    ...  \n",
       "296      Dealer       Manual      0  \n",
       "297      Dealer       Manual      0  \n",
       "298      Dealer       Manual      0  \n",
       "299      Dealer       Manual      0  \n",
       "300      Dealer       Manual      0  \n",
       "\n",
       "[301 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "['Petrol' 'Diesel' 'CNG']\n",
      "['Dealer' 'Individual']\n",
      "['Manual' 'Automatic']\n",
      "[0 1 3]\n"
     ]
    }
   ],
   "source": [
    "Car_Name = df[\"Car_Name\"].nunique()\n",
    "Fuel_Type = df[\"Fuel_Type\"].unique()\n",
    "Seller_Type = df[\"Seller_Type\"].unique()\n",
    "Transmission = df[\"Transmission\"].unique() \n",
    "Owner = df[\"Owner\"].unique()\n",
    "print(Car_Name)\n",
    "print(Fuel_Type )\n",
    "print(Seller_Type)\n",
    "print(Transmission)\n",
    "print(Owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Car_Name',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Present_Price</th>\n",
       "      <th>Kms_Driven</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Fuel_Type_Diesel</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "      <th>Seller_Type_Individual</th>\n",
       "      <th>Transmission_Manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.59</td>\n",
       "      <td>27000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.54</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.25</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.87</td>\n",
       "      <td>42450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2016</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>33988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2015</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2009</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.00</td>\n",
       "      <td>87934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017</td>\n",
       "      <td>11.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Selling_Price  Present_Price  Kms_Driven  Owner  Fuel_Type_Diesel  \\\n",
       "0    2014           3.35           5.59       27000      0                 0   \n",
       "1    2013           4.75           9.54       43000      0                 1   \n",
       "2    2017           7.25           9.85        6900      0                 0   \n",
       "3    2011           2.85           4.15        5200      0                 0   \n",
       "4    2014           4.60           6.87       42450      0                 1   \n",
       "..    ...            ...            ...         ...    ...               ...   \n",
       "296  2016           9.50          11.60       33988      0                 1   \n",
       "297  2015           4.00           5.90       60000      0                 0   \n",
       "298  2009           3.35          11.00       87934      0                 0   \n",
       "299  2017          11.50          12.50        9000      0                 1   \n",
       "300  2016           5.30           5.90        5464      0                 0   \n",
       "\n",
       "     Fuel_Type_Petrol  Seller_Type_Individual  Transmission_Manual  \n",
       "0                   1                       0                    1  \n",
       "1                   0                       0                    1  \n",
       "2                   1                       0                    1  \n",
       "3                   1                       0                    1  \n",
       "4                   0                       0                    1  \n",
       "..                ...                     ...                  ...  \n",
       "296                 0                       0                    1  \n",
       "297                 1                       0                    1  \n",
       "298                 1                       0                    1  \n",
       "299                 0                       0                    1  \n",
       "300                 1                       0                    1  \n",
       "\n",
       "[301 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.heatmap(df.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Selling_Price', axis = 1)\n",
    "y = df['Selling_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[0:300,:]\n",
    "xtest = x.iloc[300:301,:]\n",
    "ytest = y.iloc[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x.iloc[0:300,:]\n",
    "y1 = y.iloc[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Present_Price</th>\n",
       "      <th>Kms_Driven</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Fuel_Type_Diesel</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "      <th>Seller_Type_Individual</th>\n",
       "      <th>Transmission_Manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.59</td>\n",
       "      <td>27000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.54</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>6.87</td>\n",
       "      <td>42450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2015</td>\n",
       "      <td>13.09</td>\n",
       "      <td>60076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.60</td>\n",
       "      <td>33988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.90</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2009</td>\n",
       "      <td>11.00</td>\n",
       "      <td>87934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2017</td>\n",
       "      <td>12.50</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Present_Price  Kms_Driven  Owner  Fuel_Type_Diesel  \\\n",
       "0    2014           5.59       27000      0                 0   \n",
       "1    2013           9.54       43000      0                 1   \n",
       "2    2017           9.85        6900      0                 0   \n",
       "3    2011           4.15        5200      0                 0   \n",
       "4    2014           6.87       42450      0                 1   \n",
       "..    ...            ...         ...    ...               ...   \n",
       "295  2015          13.09       60076      0                 1   \n",
       "296  2016          11.60       33988      0                 1   \n",
       "297  2015           5.90       60000      0                 0   \n",
       "298  2009          11.00       87934      0                 0   \n",
       "299  2017          12.50        9000      0                 1   \n",
       "\n",
       "     Fuel_Type_Petrol  Seller_Type_Individual  Transmission_Manual  \n",
       "0                   1                       0                    1  \n",
       "1                   0                       0                    1  \n",
       "2                   1                       0                    1  \n",
       "3                   1                       0                    1  \n",
       "4                   0                       0                    1  \n",
       "..                ...                     ...                  ...  \n",
       "295                 0                       0                    1  \n",
       "296                 0                       0                    1  \n",
       "297                 1                       0                    1  \n",
       "298                 1                       0                    1  \n",
       "299                 0                       0                    1  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scal = StandardScaler()\n",
    "scal.fit(x)\n",
    "x1 = scal.transform(x1)\n",
    "xtest = scal.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forst regressor algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.3785]\n",
      "[0.92223761 0.77305831 0.9688711  0.85560028]\n",
      "0.879941824509878\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc =  RandomForestRegressor(n_estimators =100)\n",
    "rfc.fit(x1,y1)\n",
    "Y_rfpred = rfc.predict(xtest)\n",
    "print(Y_rfpred)\n",
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "score = cvs(rfc,x,y,cv=4)\n",
    "print(score)\n",
    "print(score.mean())\n",
    "print(xtest.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.8s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.9s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=250, min_samples_split=16, min_samples_leaf=13, max_depth=7, criterion=mae, total=   0.7s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae \n",
      "[CV]  n_estimators=150, min_samples_split=2, min_samples_leaf=3, max_depth=2, criterion=mae, total=   0.4s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse \n",
      "[CV]  n_estimators=150, min_samples_split=10, min_samples_leaf=7, max_depth=6, criterion=mse, total=   0.3s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   0.9s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.3s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.2s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.0s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.1s\n",
      "[CV] n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae \n",
      "[CV]  n_estimators=300, min_samples_split=2, min_samples_leaf=5, max_depth=6, criterion=mae, total=   1.1s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae \n",
      "[CV]  n_estimators=200, min_samples_split=8, min_samples_leaf=13, max_depth=8, criterion=mae, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.4s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.2s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.3s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.2s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.2s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.3s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.3s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.2s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.1s\n",
      "[CV] n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae \n",
      "[CV]  n_estimators=350, min_samples_split=14, min_samples_leaf=7, max_depth=7, criterion=mae, total=   1.1s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.5s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.5s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.5s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.6s\n",
      "[CV] n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=350, min_samples_split=10, min_samples_leaf=1, max_depth=1, criterion=mse, total=   0.5s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.3s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.3s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.2s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.3s\n",
      "[CV] n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1242, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=0, min_samples_leaf=1, max_depth=0, criterion=mae, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse \n",
      "[CV]  n_estimators=100, min_samples_split=8, min_samples_leaf=5, max_depth=1, criterion=mse, total=   0.2s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   0.9s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n",
      "[CV] n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse \n",
      "[CV]  n_estimators=500, min_samples_split=12, min_samples_leaf=11, max_depth=8, criterion=mse, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=6, min_samples_leaf=7, min_samples_split=10,\n",
      "                      n_estimators=150)\n",
      "{'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_depth': 6, 'criterion': 'mse'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rfc1 =  RandomForestRegressor()\n",
    "lr = { 'n_estimators':[100,150,200,250,300,350,400,450,500],\n",
    "    'criterion':[\"mse\", \"mae\"],\n",
    "    'max_depth': [0,1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_samples_split':[0,1,2,4,6,8,10,12,14,16],\n",
    "    'min_samples_leaf':[0,1,3,5,7,9,11,13]}\n",
    "random = RandomizedSearchCV(estimator =rfc1 ,param_distributions=lr , scoring = 'r2', cv =10 , n_iter = 10, verbose =2)\n",
    "random.fit(x1,y1)\n",
    "print(random.best_estimator_)\n",
    "print(random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2151631028116713"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.24921113])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.92719665e+24  7.39697800e-01  2.49184280e-02  7.65221446e-01]\n",
      "-1.731799163494898e+24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x1,y1)\n",
    "f = lr.predict(xtest)\n",
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "score = cvs(lr,x1,y1,cv=4)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.91918692]\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada =  AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=0, loss=linear, learning_rate=0.1 ..................\n",
      "[CV] ... n_estimators=0, loss=linear, learning_rate=0.1, total=   0.0s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.1, total=   0.2s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.1s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=exponential, learning_rate=0.5 ...........\n",
      "[CV]  n_estimators=150, loss=exponential, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.1s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=linear, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.7 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.7, total=   0.3s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n",
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.9 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . n_estimators=100, loss=square, learning_rate=0.9, total=   0.2s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=square, learning_rate=0.5 ................\n",
      "[CV] . n_estimators=150, loss=square, learning_rate=0.5, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=150, loss=linear, learning_rate=0.1 ................\n",
      "[CV] . n_estimators=150, loss=linear, learning_rate=0.1, total=   0.3s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n",
      "[CV] n_estimators=0, loss=exponential, learning_rate=0.9 .............\n",
      "[CV]  n_estimators=0, loss=exponential, learning_rate=0.9, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1007, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 117, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1011, in _validate_estimator\n",
      "    super()._validate_estimator(\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 134, in _validate_estimator\n",
      "    raise ValueError(\"n_estimators must be greater than zero, \"\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(learning_rate=0.1, n_estimators=100)\n",
      "{'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "lr1 = { 'n_estimators':[0,100,150],\n",
    "    'learning_rate':[0.1,0.3,0.5,0.7,0.9,1.0],\n",
    "     'loss' : ['linear', 'square', 'exponential'] }\n",
    "random1 = RandomizedSearchCV(estimator =ada ,param_distributions=lr1 ,scoring = 'r2', cv =10 , n_iter = 10, verbose =2)\n",
    "random1.fit(x1,y1)\n",
    "print(random1.best_estimator_)\n",
    "print(random1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.808203325006033"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.32344086])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random1.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model saving using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(random1,open(\"car_price_predmodel_ada\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(lr,open(\"car_price_predmodel_lr\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(random,open(\"car_price_predmodel_rfr\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(scal,open(\"data_transform_model\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
